import { Callout, Tabs } from "nextra/components";

# OpenAI Chat Completion

_If you're using OpenAI chat completions in Python, you can get set up in just **2 minutes**_

<Tabs items={["OpenAI Wrapper (Easy)", "API Request", "Python SDK"]}>
  
  <Tabs.Tab>
    ##### 1. Install the Python SDK

    Run `pip install athina-logger`

    ##### 2. Import Athina Logger

    Replace your `import openai` with this:

    ```python
    from athina_logger.api_key import AthinaApiKey
    from athina_logger.athina_meta import AthinaMeta
    from athina_logger.openai_wrapper import openai

    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    ```

    ##### 3. Set Athina API key

    ```python
    # Initialize the Athina API key somewhere in your code
    AthinaApiKey.set_api_key(os.getenv('ATHINA_API_KEY'))
    ```

    ##### 4. Use OpenAI chat completions request as you do normally
    Non streaming example:
    ```python
    # Use client.chat.completions.create just as you would normally
    # Add fields to AthinaMeta for better segmentation of your data
    client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        stream=False,
        athina_meta=AthinaMeta(
            prompt_slug="yc_rag_v1",
            user_query="How much funding does Y Combinator provide?", # For RAG Q&A systems, log the user's query
            context={"information": retrieved_documents} # Your retrieved documents
            session_id=session_id, # Conversation ID
            customer_id=customer_id, # Your Customer's ID
            customer_user_id=customer_id, # Your End User's ID
            environment=environment, # Environment (production, staging, dev, etc)
            external_reference_id="ext_ref_123456",
            custom_attributes={
                "name": "John",
                "age": 30,
                "city": "New York"
            } # Your custom-attributes
        ),
    )
    ```
    Streaming example:
    ```python
    stream = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        stream=True,
        athina_meta=AthinaMeta(
            prompt_slug="yc_rag_v1",
            user_query="How much funding does Y Combinator provide?", # For RAG Q&A systems, log the user's query
            context={"information": retrieved_documents} # Your retrieved documents
            session_id=session_id, # Conversation ID
            customer_id=customer_id, # Your Customer's ID
            customer_user_id=customer_id, # Your End User's ID
            environment=environment, # Environment (production, staging, dev, etc)
            external_reference_id="ext_ref_123456",
            custom_attributes={
                "name": "John",
                "age": 30,
                "city": "New York"
            } # Your custom-attributes
        ),
    )
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
    ```
    <Callout>
    Note: We support both `stream=True` and `stream=False` for OpenAI chat completions. OpenAI doesnâ€™t provide usage statistics such as prompt and completion tokens when streaming. However, We overcomes this limitation by getting these with the help of the tiktoken package, which is designed to work with all tokenized OpenAI GPT models.
    </Callout>

    ---

    ### Frequently Asked Questions

    ##### Q. What is AthinaMeta

    _The `AthinaMeta` fields are used for segmentation of your data on the dashboard. All these fields are optional, but highly recommended._

    ```python
    class AthinaMeta:
        prompt_slug: Optional[str] = None
        context: Optional[dict] = None
        customer_id: Optional[dict] = None
        customer_user_id: Optional[dict] = None
        session_id: Optional[dict] = None
        user_query: Optional[dict] = None
        environment: Optional[dict] = None
        external_reference_id: Optional[dict] = None
        customer_id: Optional[str] = None
        customer_user_id: Optional[str] = None
        response_time: Optional[int] = None
        custom_attributes: Optional[dict] = None
    ```


    ##### Q. Is this SDK going to make a proxy request to OpenAI through Athina?

    Nope! We know how important your OpenAI inference call is, so we don't want to interfere with that or increase response times.

    Instead, we simply make an logging API request to Athina, which is separate from your OpenAI request.

    ##### Q. Will this SDK increase my latency?

    Nope! The logging call is being made in a background thread as a fire and forget request, so there is almost no additional latency (< 5ms).

  </Tabs.Tab>
  
  <Tabs.Tab>
    ### Log via API Request

    See instructions [here](/logging/log_via_api).

  </Tabs.Tab>

  <Tabs.Tab>
    ### Log via Python SDK

    See instructions [here](/logging/log_via_python_sdk).
  </Tabs.Tab>

</Tabs>
