## Logging

To get started with Athina's Monitoring, the first step is to start logging your inferences.

Logging instructions may vary slightly, depending on which LLM provider you are using.

#### Logging Instructions by Provider

- [OpenAI Chat Completion (1.x)](/logging/openai_chat_1)
- [OpenAI Chat Completion (0.x)](/logging/openai_chat_0)
- [OpenAI Completion (1.x)](/logging/openai_completion_1)
- [OpenAI Completion (0.x)](/logging/openai_completion_0)
- [Anthropic](/logging/anthropic)
- [Langchain](/logging/langchain)
- [Meta Llama](/logging/meta_llama)
- [All Other Models](/logging/misc)

#### FAQs

- [Will Athina logging add additional latency](/logging/faq/logging_latency)
- [Do I have to use Athina as a proxy for logging](/logging/faq/proxy)
- [Where is my data stored](/logging/faq/data_policy)
