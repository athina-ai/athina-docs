import { Callout } from "nextra/components";

## Logging

To get started with Athina's Monitoring, the first step is to start logging your inferences.


#### Quick Start
- [OpenAI with Python](/quick_start): Just 3 lines of code.
- [LiteLLM](https://docs.litellm.ai/docs/observability/athina_integration): Just 2 lines of code.
- [Langchain](/logging/langchain): Set up in 2 minutes.
- [Log using a single POST Request](/logging/log_via_api)

If you are using **OpenAI with streaming**, then follow these instructions:

- [OpenAI Chat Completion (1.x)](/logging/openai_chat_1)
- [OpenAI Chat Completion (0.x)](/logging/openai_chat_0)
- [OpenAI Completion (1.x)](/logging/openai_completion_1)
- [OpenAI Completion (0.x)](/logging/openai_completion_0)

If you are using **OpenAI Assistant**, then follow these instructions:
- [OpenAI Assistant](/logging/openai_assistant)

**For all other models, follow these instructions:**

- [Log via API](/logging/log_via_api)

---

### FAQs

- [Will Athina logging add additional latency](/logging/faq/logging_latency)
- [Do I have to use Athina as a proxy for logging](/logging/faq/proxy)
- [Where is my data stored](/logging/faq/data_policy)
