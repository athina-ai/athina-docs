# Intro to Evals

It's difficult to know if your LLM response is good or bad. Most developers start out by simply eyeballing the responses.
This is fine when you're building a prototype and testing on 5-10 examples.

But once you optimize for reliability in production, this method breaks down.

Evals can help you:

- detect regressions
- measure performance of model (as defined by your goals)
- A/B test different models and prompts rapidly
- Monitor production data with confidence
- Run quantifiable experiments against ambiguous conversations (\*)

Think of evals like unit tests for your LLM app.

_\*Here's a great [video](https://youtu.be/XGJNo8TpuVA?feature=shared&t=1140) by OpenAI where an AI Engineer explains why and how to use evals._
