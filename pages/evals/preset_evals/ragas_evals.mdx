import { Callout } from "nextra/components";

## RAGAS Based Metrics

[Github](https://github.com/athina-ai/athina-evals/blob/main/athina/evals/ragas/ragas_evaluator.py)

## ❊ Info

These evaluators are RAGAS based evaluators.


##### ▷ Run the RAGAS eval on a single datapoint

```python
from athina.evals import RagasAnswerRelevancy

data = {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "response": "Tesla is an electric car",
    }
eval_model = "gpt-3.5-turbo"
RagasAnswerRelevancy(model=eval_model).run(**data).to_df()
```

---

##### ▷ Run the RAGAS eval on a dataset

1. Load your data with the `RagasLoader`

```python
from athina.loaders import RagasLoader
data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "response": "Tesla is an electric car",
    },
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Paris is the capital of france"],
        "response": "France is in western Europe and Paris is its capital",
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

```

2. Run the evaluator on your dataset

```python
from athina.evals import RagasAnswerRelevancy

eval_model = "gpt-3.5-turbo"
RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset).to_df()
```

---

## Following are the different RAGAS evals supported by Athina

### Faithfulness

**Description:**
Checks the factual consistency of the generated llm response against the retrieved context

[RAGAS Docs](https://docs.ragas.io/en/latest/concepts/metrics/faithfulness.html)

**Required Args**

- `query`: User Query 
- `contexts`: List of retrieved context your LLM response should be faithful to
- `response`: The LLM generated response

**Default Engine:** `gpt-4-1106-preview`

**Sample Code:**

```python
from athina.loaders import RagasLoader
from athina.evals import RagasFaithfulness

data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "response": "Tesla is an electric car",
    },
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Paris is the capital of france"],
        "response": "France is in western Europe and Paris is its capital",
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

eval_model = "gpt-3.5-turbo"
RagasFaithfulness(model=eval_model).run_batch(data=dataset).to_df()
```

### Answer Relevancy

**Description:**
Checks how relevant is llm response with respect to the query

[RAGAS Docs](https://docs.ragas.io/en/latest/concepts/metrics/answer_relevance.html)

**Required Args**

- `query`: User Query 
- `contexts`: List of retrieved context your LLM response should be faithful to
- `response`: The LLM generated response

**Default Engine:** `gpt-4-1106-preview`

**Sample Code:**

```python
from athina.loaders import RagasLoader
from athina.evals import RagasAnswerRelevancy

data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "response": "Tesla is an electric car",
    },
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Paris is the capital of france"],
        "response": "France is in western Europe and Paris is its capital",
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

eval_model = "gpt-3.5-turbo"
RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset).to_df()
```

### Context Precision

**Description:**
Checks how precise is context with respect to the expected response

[RAGAS Docs](https://docs.ragas.io/en/latest/concepts/metrics/context_precision.html)

**Required Args**

- `query`: User Query 
- `contexts`: List of retrieved context your LLM response should be faithful to
- `expected_response`: Expected LLM Response

**Default Engine:** `gpt-4-1106-preview`

**Sample Code:**

```python
from athina.loaders import RagasLoader
from athina.evals import RagasContextPrecision

data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "expected_response": "France is in europe. Paris is it's capital"
    },
    {
        "query": "What is Tesla? Who founded it?",
        "contexts": ["Tesla is the electric car company. Tesla is registerd in United States", "Elon Musk founded it"],
        "expected_response": "Tesla is an electric car company. Elon Musk founded it."
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

eval_model = "gpt-3.5-turbo"
RagasContextPrecision(model=eval_model).run_batch(data=dataset).to_df()
```

### Context Relevancy

**Description:**
Checks how relevant is context with respect to the user query

[RAGAS Docs](https://docs.ragas.io/en/latest/concepts/metrics/context_relevancy.html)

**Required Args**

- `query`: User Query 
- `contexts`: List of retrieved context your LLM response should be faithful to

**Default Engine:** `gpt-4-1106-preview`

**Sample Code:**

```python
from athina.loaders import RagasLoader
from athina.evals import RagasContextRelevancy

data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Paris is the capital of France"],
    },
    {
        "query": "What is Tesla? Who founded it?",
        "contexts": ["Tesla is the electric car company. Tesla is registerd in United States", "Elon Musk founded it"],
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

eval_model = "gpt-3.5-turbo"
RagasContextRelevancy(model=eval_model).run_batch(data=dataset).to_df()
```

### Context Recall

**Description:**
Measures the extent to which the retrieved context aligns with the expected llm response

[RAGAS Docs](https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html)

**Required Args**

- `query`: User Query 
- `contexts`: List of retrieved context your LLM response should be faithful to
- `expected_response`: Expected LLM Response

**Default Engine:** `gpt-4-1106-preview`

**Sample Code:**

```python
from athina.loaders import RagasLoader
from athina.evals import RagasContextRecall

data = [
    {
        "query": "Where is France and what is it's capital?",
        "contexts": ["France is the country in europe known for delicious cuisine", "Tesla is an electric car", "Elephant is an animal"],
        "expected_response": "France is in europe. Paris is it's capital"
    },
    {
        "query": "What is Tesla? Who founded it?",
        "contexts": ["Tesla is the electric car company. Tesla is registerd in United States", "Elon Musk founded it"],
        "expected_response": "Tesla is an electric car company. Elon Musk founded it."
    },
]

# Load the data from CSV, JSON, Athina or Dictionary
dataset = RagasLoader().load_dict(data)

eval_model = "gpt-3.5-turbo"
RagasContextRecall(model=eval_model).run_batch(data=dataset).to_df()
```