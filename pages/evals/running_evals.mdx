import { Callout } from "nextra/components";

# Running Evals

There are a few ways to run evals using Athina:

## Run an Eval manually from the Inference Page

1. Open the inference you want to evaluate, and click the "Run Eval" button (located towards the top-right).
2. Choose the evaluation you want to run (Note: function evals cannot be run from the inference page).
3. Choose the LLM engine for your evaluation.

Eval results will appear shortly in the Evals tab on the right.

<br />

<img
  src="/run-eval-manually.gif"
  alt="Run an eval manually from the inference page"
/>

## Continuous Evaluation

If you configure evaluations in the dashboard at https://app.athina.ai/evals/config, they will run automatically against all logged inferences that meet your filters.

- [How to configure automatic evals](/evals/automatic_evals)

**Note:** Logs may be sampled to ensure that evaluations run within your configured limits. You can adjust these limits in the [Settings](https://app.athina.ai/settings) page.

**Note: Continuous evaluation is only available for paid plans. Contact hello@athina.ai to upgrade your plan.**

---

## Programmatic Evals

<Callout>

Here's a 2-minute [video tutorial](https://www.loom.com/share/10e37f1ba11242ac8c97902edd2fa61e)
showcasing how you can quickly run pre-built evals, and view the results on the dashboard.

</Callout>

The easiest way to get started is to use one of our [Example Notebooks](/evals/cookbooks) as a starting point.

For more detailed guides, you can follow the links below to get started running evals using Athina.

- [Quick Start Guide](/evals/quick_start)
- [Run an eval](/evals/running_evals/run_eval)
- [Run an eval suite](/evals/running_evals/run_eval_suite)
- [Customize an eval](/evals/custom_evals)
- [View Results on Athina Dashboard](/evals/develop_dashboard)
- [Loading Data for Evals](/evals/loading_data)

## Running Evals as Realtime Guardrails

Follow this [example notebook](https://github.com/athina-ai/athina-evals/blob/main/examples/guard.ipynb)
